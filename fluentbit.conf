[SERVICE]
    flush        1
    log_level    trace # TODO change to info when all is working well
    parsers_file parsers.conf
    parsers_file /home/vcap/deps/0/apt/etc/fluent-bit/parsers.conf
    plugins_File plugins.conf

[INPUT]
    name      dummy
    dummy     {"message":"A simple test message", "temp": "0.74", "extra": "false"}
    samples   1

[INPUT]
    name tcp
    port 8888
    format none

# Ship to s3:
#
# TODO:
#  - Refer to extracted env vars in the config below
[OUTPUT]
    Name s3
    Match *
    bucket ${BUCKET_NAME}
    region ${AWS_DEFAULT_REGION}
    json_date_key time
    json_date_format iso8601
    # TODO: will fluent-bit reliably upload partial data upon shutdown? Persistent storage may be desirable.
    store_dir /tmp/fluent-bit/s3
    total_file_size 50M
    upload_timeout 10m
    # TODO: modify s3_key_format -- by app?
    # 2023-09-22T18:35:47.45-0700 [APP/PROC/WEB/SIDECAR/FLUENTBIT/0] ERR [2023/09/23 01:35:47] [ info] [output:s3:s3.0] Successfully uploaded object /fluent-bit-logs/tcp.1/2023/09/23/01/25/39-object7fe2lXYa
    s3_key_format /fluent-bit-logs/$TAG/%Y/%m/%d/%H/%M/%S
    retry_limit 5
    # TODO: do we care about data ordering?
    preserve_data_ordering On

# Ship to New Relic:
[OUTPUT]
    Name newrelic
    Match *
    licenseKey ${NEW_RELIC_LICENSE_KEY}
    endpoint ${NEW_RELIC_LOGS_ENDPOINT}

# # Uncomment to see the parsed messages in the logshipper's logs:
# [OUTPUT]
#     name stdout
#     match *

### Filters run in order of appearance ###

# Initial pass at parsing the body of the request.
[FILTER]
    name parser
    match tcp.*
    key_name log
    parser post-with-syslog
    reserve_data Off
    preserve_key On

# Further filter of the already-extracted fields
[FILTER]
    name parser
    match tcp.*
    key_name message
    parser extract-gauge
    reserve_data On
    preserve_key On

# And so on ... (multiple passes let us capture fields in varying order)
[FILTER]
    name parser
    match tcp.*
    key_name message
    parser extract-tags
    reserve_data On
    preserve_key On

[FILTER]
    name parser
    match tcp.*
    key_name message
    parser extract-remainder
    reserve_data On
    preserve_key On

[FILTER]
    name parser
    match tcp.*
    key_name remainder
    parser extract-json-object-from-remainder
    reserve_data On
    preserve_key On

# Process selected keys (tags, gauge) into (stringified) JSON
[FILTER]
    name lua
    match tcp.*
    time_as_table On
    script scripts/parse_keys_with_eq_pairs.lua
    call parse_keys_with_eq_pairs

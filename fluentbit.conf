[SERVICE]
    flush        1
    log_level    trace # TODO change to info when all is working well
    parsers_file parsers.conf
    parsers_file /home/vcap/deps/0/apt/etc/fluent-bit/parsers.conf
    plugins_File plugins.conf

[INPUT]
    name      dummy
    dummy     {"message":"A simple test message", "temp": "0.74", "extra": "false"}
    samples   1

[INPUT]
    name tcp
    port 8888
    format none

# Uncomment to ship to s3
#
# TODO:
#  - Refer to extracted env vars in the config below
# [OUTPUT]
#      Name s3
#      Match *
#      bucket your-bucket
#      region us-east-1
#      store_dir /home/ec2-user/buffer
#      total_file_size 50M
#      upload_timeout 10m

# Uncomment to ship to New Relic
# [OUTPUT]
#     Name newrelic
#     Match *
#     licenseKey ${NEW_RELIC_LICENSE_KEY}
#     endpoint ${NEW_RELIC_LOGS_ENDPOINT}

# Uncomment to see the parsed messages in the logshipper's logs:
[OUTPUT]
    name stdout
    match *

### Filters run in order of appearance ###

# Initial pass at parsing the body of the request.
[FILTER]
    name parser
    match tcp.*
    key_name log
    parser post-with-syslog
    reserve_data Off
    preserve_key On

# Further filter of the already-extracted fields
[FILTER]
    name parser
    match tcp.*
    key_name message
    parser extract-gauge
    reserve_data On
    preserve_key On

# And so on ... (multiple passes let us capture fields in varying order)
[FILTER]
    name parser
    match tcp.*
    key_name message
    parser extract-tags
    reserve_data On
    preserve_key On

# Process selected keys (tags, gauge) into (stringified) JSON
[FILTER]
    name lua
    match tcp.*
    time_as_table On
    script scripts/parse_keys_with_eq_pairs.lua
    call parse_keys_with_eq_pairs
